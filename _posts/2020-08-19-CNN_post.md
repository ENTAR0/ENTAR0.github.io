---
title: CNN(Convolutional Neural Network) 정리
categories:
- Deep learning
last_modified_at: 2020-08-28T14:00:00+09:00
tags:
- Deep learning
- Machine learning
- Image Processing
toc: true
---
# 1. Intro
CNN을 처음 알게되었을때 CNN은 인간이 물체를 식별하는 방식을 모방한 것일까? 아니면 그냥 블랙박스일까?, 학습된 필터는 무엇을 보고있는것일까?, 어떻게 CNN은 FCL과는 다르게 reliance of position에 무관하단것일까? 등등 여러 궁금증이 떠올랐다. 그리고 여러 자료를 찾아본 결과 그 궁금증을 많이 해소 해주는 강의를 찾아 그 강의를 바탕으로 CNN에 대해 정리해보고자 작성하였다.  
[Convolutional Neural Networks | MIT 6.S191](https://youtu.be/iaSUYvmCekI)와
[ Understanding Sub-Sampling Layers Within Deep Learning](https://towardsdatascience.com/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551), [CNN 개요](https://blog.naver.com/laonple/220587920012), [시각정보 처리과정](https://aidalab.tistory.com/23)을 참고하였다.
# 2. Why CNN?
이미지 처리에 있어서 기존에 있는 MLP방식을 사용하지않고 CNN방식을 사용하는것은 CNN을 사용함으로써 얻을 수 있는 이득이 상당하기 때문이다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/90860659-5efe2d80-e3c5-11ea-8a11-9d2575274a9c.png"></p>
왜냐하면 위에 보이는 이미지 처럼 MLP의 경우에는 픽셀 하나 하나 뉴런의 입력데이터로 받아 처리한다. 이 경우 모델은 이미지의 raw data를 학습하기 때문에 postion 정보에 민감해질 수 밖에 없다. 그래서 이 모델의 입력데이터로 변형된 A의 이미지를 줬을때 A에 대한 정확한 판별을 진행할 수 없다. 하지만 CNN의 경우에는 A가 포함된 이미지에서 A에 대한 features를 뽑아내어서 그 features를 바탕으로 판별하기 때문에 변형된 A에 대해 더욱 유연한 처리를 할 수 있게 된다. 한마디로 모델이 spatial information을 가진다는 것이다. 또한 FCL의 경우 16*16 이미지를 처리하는데 28326개의 parameters가 필요하다. 하지만 일반적인 학습에는 더 큰 해상도의 이미지가 들어가 parameters 개수가 급격하게 증가해 학습 처리속도에 많은 부정적인 영향을 준다. 이외에도 많은 이유가 있다. 간단히 살펴보자면 아래와 같은것들이 있다.

- Sharing parameters를 사용해 학습 parameter 개수를 줄일 수 있음
- Spatial Information, Locality, translation invariance를 가짐
- sub-sampling을 사용해 불필요한 세부사항 정보를 제거


# 3. What computers see
그렇다면 이러한 CNN모델에 기반이 되는 컴퓨터는 무엇을 보고 있을까? 기본적으로 사람은 왼쪽에 사진을 보고있지만 컴퓨터는 오른쪽 이미지처럼 색이 2차원 행렬로 변환된 값들을 보고 있다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/91566494-bdf01380-e97e-11ea-9aa2-19884c55cb2f.png"></p>
그리고 이러한 값들을 기반으로 아래의 pipeline을 따라 feature extraction을 수행한다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/91590175-e6373c80-e995-11ea-9823-613b818b496a.png"></p>
 하지만 이러한 기능을 수행 하면서 객체 간의 스케일이라던지 바라보는 시점, Brightness와 Contrast의 차이, 왜곡등 여러 변수들 때문에 feature extraction을 수행하는데 문제가 생길 수 있다.

# 4. Learning visual features
그렇다면 어떤 방식을 사용해야 여러 변수들에 민감하지 않게 정확한 시각 정보를 컴퓨터에게 학습시킬 수 있을까?


# 5. Feature extraction and convolution


# 6. Convolution neural networks


# 7. Non-linearity and pooling


# 8. code example


# 9. Applications


# 10. End-to-end self Driving cars
