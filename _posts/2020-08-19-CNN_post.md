---
title: CNN(Convolutional Neural Network) 정리
categories:
- Deep learning
last_modified_at: 2020-09-04T14:00:00+09:00
tags:
- Deep learning
- Machine learning
- Image Processing

toc: true
---
# 1. Intro
합성곱 신경망(Convolutional Neural Network)을 처음 알게되었을때 합성곱 신경망은 인간이 물체를 식별하는 방식을 모방한 것일까? 아니면 그냥 블랙박스일까?, 학습된 필터는 무엇을 보고있는것일까?, 왜 합성곱 신경망은 전결합층과는 다르게 위치 의존도(reliance of position)에 무관하단것일까? 등등 여러 궁금증이 떠올랐다. 그리고 여러 자료를 찾아본 결과 그 궁금증을 많이 해소 해주는 강의를 찾아 그 강의를 바탕으로 합성곱 신경망에 대해 정리해보고자 작성하였습니다.  
[Convolutional Neural Networks | MIT 6.S191](https://youtu.be/iaSUYvmCekI)와
[ Understanding Sub-Sampling Layers Within Deep Learning](https://towardsdatascience.com/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551), [CNN 개요](https://blog.naver.com/laonple/220587920012), [시각정보 처리과정](https://aidalab.tistory.com/23)을 참고하였습니다.
# 2. Why CNN?
이미지 처리에 있어서 기존에 있는 전결합층(Fully-Connected-Layer)방식을 사용하지않고 합성곱 신경망 방식을 사용하는것은 합성곱 신경망을 사용함으로써 얻을 수 있는 이득이 상당하기 때문입니다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/90860659-5efe2d80-e3c5-11ea-8a11-9d2575274a9c.png"></p>
<p align="center">출처:<a href = "https://blog.naver.com/laonple/220587920012">&lt;CNN 개요&gt;</a></p>
왜냐하면 위에 보이는 이미지 처럼 전결합층의 경우에는 픽셀 하나 하나 뉴런의 입력데이터로 받아 처리합니다. 이 경우 모델은 이미지의 Raw data를 학습하기 때문에 위치(Position) 정보에 민감해질 수 밖에 없습니다. 그래서 이 모델의 입력데이터로 변형된 A의 이미지를 줬을때 A에 대한 정확한 판별을 진행할 수 없습니다. 하지만 합성곱 신경망의 경우에는 A가 포함된 이미지에서 A에 대한 특징(Feature)들을 뽑아내어서 그 특징들을 바탕으로 판별하기 때문에 변형된 A에 대해 더욱 유연한 처리를 할 수 있게 됩니다. 한마디로 모델이 공간 정보(Spatial information)을 가진다는 것입니다. 또한 전결합층의 경우 16*16 이미지를 처리하는데 28326개의 매개 변수(parameters)가 필요합니다. 하지만 일반적인 학습에는 더 큰 해상도의 이미지가 들어가 매개변수 개수가 급격하게 증가해 학습 처리에 많은 부정적인 영향을 줍니다. 이외에도 많은 이유가 있다. 간단히 살펴보자면 아래와 같은것들이 있습니다.

- Sharing parameters를 사용해 학습 parameter 개수를 줄일 수 있음
- Spatial Information, 국소성(Locality), 불변성(translation invariance)를 가짐
- Sub-sampling(Pooling)을 사용해 불필요한 세부사항 정보를 제거


# 3. What computers see
이러한 합성곱 신경망 모델에 기반이 되는 필터는 무엇을 보고 있을까? 기본적으로 사람은 왼쪽에 사진을 보고있지만 필터는 오른쪽 이미지처럼 색이 2차원 행렬로 변환된 값들을 보고 있습니다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/91566494-bdf01380-e97e-11ea-9aa2-19884c55cb2f.png"></p>
<p align="center">출처:<a href = "https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e">&lt;Everything You Ever Wanted To Know About Computer Vision&gt;</a></p>
그리고 이러한 값들을 기반으로 아래의 과정(Pipeline)을 따라 특징 추출(Feature extraction)을 수행합니다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/91590175-e6373c80-e995-11ea-9823-613b818b496a.png"></p>
 하지만 이러한 기능을 수행 하면서 객체 간의 스케일이라던지 바라보는 시점, Brightness와 Contrast의 차이, 왜곡등 여러 변수들 때문에 특징 추출을 수행하는데 문제가 생길 수 있습니다.

# 4. Learning visual features
어떤 방식을 사용해야 정확한 시각 정보를 컴퓨터에게 학습시킬 수 있을까?
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/92117010-94783180-ee2f-11ea-8383-feafaebbdef9.png"></p>
<p align="center">출처:<a href = "https://www.researchgate.net/figure/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks_fig4_316950618">&lt;Reserach gate&gt;</a></p>
이를 이해하기 위해서는 수용 영역 또는 장소야(Receptive Field) 라고 불리는 개념을 이해 해야합니다. 수용 영역은 위의 이미지 처럼 한 영역에 대해서 반응하고 다음 레이어에 이를 반영합니다. 또한 이런 과정을 거치면서 수용 영역이 겹칠 수 도 있는데 이를 통해 국소 영역간의 상관 관계에 대한 정보를 얻을 수 있습니다.


# 5. Feature extraction and convolution
수용 영역의 반응을 통해서 특징을 검출하는것을 구현한 방법이 바로 합성곱(Convolution)입니다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/91635862-d3c10f80-ea36-11ea-863d-e54ec216ba6c.png"></p>
합성곱 신경망은 입력 이미지에 대해 무작위로 초기화된 필터의 매개변수 값으로 합성곱을 수행하고 그 결과로 특징맵(Feature map)을 출력 결과로 내놓습니다. 그리고 이 특징맵들은 활성화 함수(Activation function)을 거쳐 합성곱 신경망의 최종 출력인 활성화 맵(Activation map)을 내놓게 됩니다. 그리고 이 활성화 맵은 저수준(low-level)에서는 대부분 객체의 모서리(Edge)나 덩어리진 부분(Blob)을 보고있습니다.

- 필터의 갯수는 입력 이미지의 채널 개수와 같다.
- 무작위로 초기화 하지 않으면 필터가 모두 같은 특징을 추출할 수 있다.

# 6. Convolution neural networks
본격적으로 CNN의 구조를 보면서 객체를 탐지하기 위해 어떤 방식으로 특징을 적절하게 추출하고 이를 가지고 객체가 무엇 인지를 판단하는 과정을 살펴봅시다.
<p align="center"><img src="https://user-images.githubusercontent.com/56510688/92212618-339f3680-eecd-11ea-9b25-bce7b4589148.png"></p>
<p align="center">출처:<a href = "https://kr.mathworks.com/help/deeplearning/ug/introduction-to-convolutional-neural-networks.html">&lt;Learn About Convolutional Neural Networks&gt;</a></p>
일반적으로 CNN은 두가지 부분으로 나뉘어져있습니다. 첫번째는 합성곱, 활성화 함수 그리고 Pooling계층을 포함하는 특징 검출(Feature Extraction)부분과 두번째는 전결합층과 softmax함수로 이뤄진 분류기(Classifier)부분으로 나뉩니다. 특징 검출부분에 대해 자세히 설명해 보자면, 무작위로 초기화된 필터의 매개변수 값으로 입력 이미지에 대해 Slide해 국소 영역에 대한 Feature map(다음 Conv계층의 입력으로 사용됩니다.)을 뽑아냅니다.
그리고 이 Feature map은 Activation function을 거쳐 매개 변수값을 non-linearity하게 바꾸어주고 Activation map(Conv의 깊이에 따른 추상 수준의 특징을 가집니다.)을 출력합니다. 마지막으로 Pooling계층을 거쳐 Down sampling된 이미지를 출력합니다. 위의 과정을 반복한 후 마지막으로 Classifier부분에서 뽑아낸 활성화 맵의 픽셀을 모두 연결 시켜 softmax함수로 이 활성화 맵이 어떤 객체인지에 대한 확률을 제공합니다.

- Down Sampling:객체가 객체임을 인지할 수 있는 최소단위의 특징을 뽑아내기 위해 불필요한 Detail을 제거해주는 기법이다.
- 활성화 함수(Relu)를 사용함으로써 음수값은 0으로 매핑하고 양수 값은 그대로 가져가 불필요한 특징을 제거 할 수 있다..


# 7. Non-linearity and pooling


# 8. Applications


# 9. End-to-end self Driving cars
